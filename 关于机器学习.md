# 机器学习
机器学习在很多方面都可以看作是数据科学能力延伸的主要手段。机器学习是用数据科学的计算能力和算法能力去弥补统计方法的不足，其最终结果是为那些目前既没有高效的理论支持，又没有高效的计算方法的统计推理与数据探索问题提供解决方法。
“机器学习”这个词现在太流行了，仿佛是一种万能药：**只要对数据做了机器学习，那么所有问题都可以迎刃而解！**但“理想很丰满，现实很骨感”，事实远没那么简单。虽然机器学习方法都很强大，但是如果想有效地使用这些方法，必须先掌握每种方法的优缺点，同时还要掌握一些基础的统计概念，如偏差、方差、过拟合、欠拟合等。
## 一、什么是机器学习
先看看究竟什么是机器学习，什么不是机器学习。机器学习经常被归类为人工智能（artificial intelligence）的子领域，但这种归类方法存在误导嫌疑。虽然对机器学习的研究确实是源自人工智能领域，但是机器学习的方法却应用于数据科学领域，因此把机器学习看作是一种**数学建模**可能更为恰当。

机器学习的本质就是借助数学模型理解数据。当我们给模型装上可以适应观测数据的**可调参数**时，“学习就开始了”，此时的程序被认为具有从数据中“学习”的能力。一旦模型可以拟合旧的观测数据，那么它们就可以预测并解释新的观测数据。随着理解的深入，你会慢慢发现数学模型的“学习”过程其实与人脑的“学习”过程相似。
### 1.1 机器学习的分类
机器学习一般可以分为两类：有监督学习（supervised learning）和无监督学习（unsupervised learning）。

**有监督学习**是指对数据的若干特征值与若干标签（类型）之间的关联性进行建模的过程；只要模型被确定，就可以应用到新的未知数据上。这类学习过程可以进一步**分类**（classification）任务与**回归**（regression）任务。在分类任务中，标签都是离散值；而在回归任务中，标签都是连续值。

**无监督学习**是指对不带任何标签的数据特征进行建模，通常被看成是一种“让数据自己介绍自己”的过程。这类模型包括**聚类**（clustering）任务和**降维**（dimensionality reduction）任务。聚类算法可以将数据分成不同的组别，而降维算法追求用更简洁的方式表现数据。

此外，还有一种**半监督学习**（ssemi-supervised learning）方法，介于有监督学习和无监督学习之间。该方法通常在数据标签不完整时使用。
### 1.2 机器学习应用的定性示例
下面介绍一些简单的机器学习任务示例，让抽象的理论显得具体一点。这些例子都是我们在后面内容中将要看到的机器学习任务的直观、非量化形式，之后将更深入地介绍相关模型地具体用法。
#### 1. 分类：预测离散标签
先来看一个简单的**分类**任务。假如我们有一些带标签的数据点，希望用这些信息为那些不带标签的数据点进行分类。

假如这些数据点的分布如图所示。

![img](E:/my_code/py/img/5-1.png)

我们看到的是二维数组，也就是说每个数据点都有两个**特征**，在平面上用数据点的$(x,y)$位置表示。另外，我们的数据点还用一种颜色表示一个**类型标签**，一共有两种类型，分别用两种颜色表示。我们想根据这些特征和标签创建一个模型，帮助我们判断新的数据点是“蓝色”还是“红色”。

虽然有很多可以解决分类任务的模型，但这里还是先用最简单的一种，假设平面上有一条可以将两种类型分开的直线，直线的两侧分别是一种类型。那么我们的模型其实就是“一条可以分类的直线”，而模型参数其实是直线位置与方向的数值。这些模型参数的最优解都可以通过学习数据获得（也就是机器学习的“学习”），这个过程通常被称为训练模型。

下图是为这组数据分类而训练的模型。

![img](E:/my_code/py/img/5-2.png)

模型现在已经训练好了，可以对一个新的、不带标签的数据进行分类了。也就是说，我们可以拿一组新数据，把这个模型的直线画在上面，然后根据这个模型为新数据分配标签，这个阶段通常被称为**预测**，如图所示。

![img](E:/my_code/py/img/5-3.png)

这就是机器学习中最基本的分类思想，这个“分类”指的是数据具有离散的类型标签。刚一开始，你可能会觉得分类非常简单：不就是直接观察数据，然后画一条分割线就好了。但是，机器学习方法的真正用途是要解决大型高维度数据集的分类问题。

以常见的分类任务——垃圾邮件自动识别为例。在这类任务中，我们通常会获得以下特征和标签。
1. **特征1、特征2······特征n**：垃圾邮件关键词与短语出现的频次归一化向量。
2. **标签**：“垃圾邮件”或“普通邮件”。

在训练数据集中，这些标签可能是人们通过观察少量邮件样本得到的，而剩下的大量邮件都需要通过模型来判断标签。一个训练有素的分类算法只要具备足够好的特征（通常是成千上万个词或成语），就能非常高效地进行分类。
#### 2. 回归：预测连续标签
下面要介绍的**回归**任务与离散标签分类算法相反，其标签是连续值。

如图所示的数据集，所有样本的标签都在一个连续的区间内。

![img](E:/my_code/py/img/5-4.png)

和前面的分类示例一样，我们有一个二维数组，每个数据点有两个特征。数据点的颜色表示每个点的连续标签。

虽然有很多可以处理这类数据的回归模型，但是我们还是用简单线性回归模型来预测数据。用简单线性回归模型作出假设，如果我们把标签看成是第三个维度，那么就可以将数据拟合成一个平面方程——这就是著名的在二维平面上线性拟合问题的高阶情形。

我们可以将数据可视化为下图形式。

![img](E:/my_code/py/img/5-5.png)

注意，这里特征1和特征2平面与之前的二维图形是一样的，只不过用了颜色和三维坐标轴的位置表示标签。通过这个视角，就有理由相信：如果将三维数据拟合成一个平面，就可以对任何输入参数集进行预测。回到原来的二维投影图形上，拟合平面时获得的结果如图所示。

![img](E:/my_code/py/img/5-6.png)

这个拟合平面为预测新数据点的标签提供了依据。我们可以直观地找到结果，如图所示。

![img](E:/my_code/py/img/5-7.png)

和之前介绍的分类示例类似，这个回归示例在低维度时看起来可能也非常简单。但是这些方法的真实价值在于，它们可以直接了当地处理包含大量特征的数据集。

类似的任务有计算通过天文望远镜观测到的星系的距离——在这类任务中，可能会用到以下特征与标签。

1. 特征1、2······特征n：具有若干波长或颜色的星系的亮度。
2. 标签：星系的距离或红移。

少量星系的距离可以通过直接观察（通常成本也非常高）进行测量。之后，我们就可以利用适当的回归模型估计其他星系的距离，而不需要为整个星系集合使用昂贵的观察设备。

#### 3.聚类：为无标签数据添加标签

前面介绍的回归与分类示例都是有监督学习算法，需要建立一个模型来预测新数据的标签。无监督学习涉及的模型将探索没有任何已知标签的数据。

无监督学习的普遍应用之一就是“聚类”——数据被聚类算法自动分成若干离散的组别。例如，我们有如图的一组二维数据。

![img](E:/my_code/py/img/5-8.png)

仅通过肉眼观察，就可以很清楚地判断出这些点应该属于哪个组。一个聚类模型会根据输入数据的固有结构判断数据点之间的相关性。通过最快、最直观的*k-means*聚类算法，就可以发现如图的类簇。

![img](E:/my_code/py/img/5-9.png)

*k-means*会拟合出一个由*k*个簇中心点构成的模型，最优的簇中心点需要满足簇中的每个点到该中心的总距离最短。随着数据量增大、维度增多，聚类算法对于探索数据集的信息会变得十分有效。

#### 4.降维：推断无标签数据的结构

降维是另一种无监督算法示例，需要从数据集本身的结构推断标签和其他信息。虽然降维比之前看到的示例要抽象一些，但是一般来说，降维其实就是在保证高维数据质量的条件下从中抽取出一个低维数据集。不同的降维算法用不同的方式衡量降维质量。

下图用一个示例进行演示。

![img](E:/my_code/py/img/5-10.png)

从图中可以清晰地看出数据存在某种结构：这些数据点在二维平面上按照一维螺旋线整齐地排列。从某种程度上，你可以说这些数据“本质上”只有一维，虽然这个一维数据是嵌在高维数据空间里的。适合这个示例的降维模型不仅需要满足数据的非线性嵌套结构，而且还要给出低维表现形式。

下图是通过Isomap算法得到的可视化结果，它是一种专门用于解决这类问题的流形学习算法。

![img](E:/my_code/py/img/5-11.png)

注意，图中的颜色（表示算法提取到的一维潜在变量）沿着螺旋线呈现均匀变化，表明这个算法的确发现了肉眼所能观察到的结构。

## 二、Scikit-Learn简介

目前，Python有不少可以实现各种机器学习算法的程序库，Scikit-Learn是最流行的程序包之一，它为各种常用机器学习算法提供了高效版本。

### 2.1 Scikit-Learn的数据表示

机器学习是从数据创建模型的学问，因此你首先需要了解怎样表示数据才能让计算机理解。Scikit-Learn认为数据表示最好的方法就是用数据表的形式。

#### 1.数据表

基本的数据表就是二维网格数据，其中的每一行表示数据集中的每个样本，而列表示构成每个样本的相关特征。例如**Ronald Fisher**在1936年对鸢尾花数据集的经典分析。我们用Seaborn程序库下载数据并加载到pandas的DataFrame中。