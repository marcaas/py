#机器学习
机器学习在很多方面都可以看作是数据科学能力延伸的主要手段。机器学习是用数据科学的计算能力和算法能力去弥补统计方法的不足，其最终结果是为那些目前既没有高效的理论支持，又没有高效的计算方法的统计推理与数据探索问题提供解决方法。
“机器学习”这个词现在太流行了，仿佛是一种万能药：**只要对数据做了机器学习，那么所有问题都可以迎刃而解！**但“理想很丰满，现实很骨感”，事实远没那么简单。虽然机器学习方法都很强大，但是如果想有效地使用这些方法，必须先掌握每种方法的优缺点，同时还要掌握一些基础的统计概念，如偏差、方差、过拟合、欠拟合等。
## 一、什么是机器学习
先看看究竟什么是机器学习，什么不是机器学习。机器学习经常被归类为人工智能（artificial intelligence）的子领域，但这种归类方法存在误导嫌疑。虽然对机器学习的研究确实是源自人工智能领域，但是机器学习的方法却应用于数据科学领域，因此把机器学习看作是一种**数学建模**可能更为恰当。
机器学习的本质就是借助数学模型理解数据。当我们给模型装上可以适应观测数据的**可调参数**时，“学习就开始了”，此时的程序被认为具有从数据中“学习”的能力。一旦模型可以拟合旧的观测数据，那么它们就可以预测并解释新的观测数据。随着理解的深入，你会慢慢发现数学模型的“学习”过程其实与人脑的“学习”过程相似。
### 1.1 机器学习的分类
机器学习一般可以分为两类：有监督学习（supervised learning）和无监督学习（unsupervised learning）。
**有监督学习**是指对数据的若干特征值与若干标签（类型）之间的关联性进行建模的过程；只要模型被确定，就可以应用到新的未知数据上。这类学习过程可以进一步**分类**（classification）任务与**回归**（regression）任务。在分类任务中，标签都是离散值；而在回归任务中，标签都是连续值。
**无监督学习**是指对不带任何标签的数据特征进行建模，通常被看成是一种“让数据自己介绍自己”的过程。这类模型包括**聚类**（clustering）任务和**降维**（dimensionality reduction）任务。聚类算法可以将数据分成不同的组别，而降维算法追求用更简洁的方式表现数据。
此外，还有一种**半监督学习**（ssemi-supervised learning）方法，介于有监督学习和无监督学习之间。该方法通常在数据标签不完整时使用。
### 1.2 机器学习应用的定性示例
下面介绍一些简单的机器学习任务示例，让抽象的理论显得具体一点。这些例子都是我们在后面内容中将要看到的机器学习任务的直观、非量化形式，之后将更深入地介绍相关模型地具体用法。
#### 1. 分类：预测离散标签
先来看一个简单的**分类**任务。假如我们有一些带标签的数据点，希望用这些信息为那些不带标签的数据点进行分类。
假如这些数据点的分布如图所示。
![图片](E:/my_code/py/img/5-1.png)
我们看到的是二维数组，也就是说每个数据点都有两个**特征**，在平面上用数据点的$(x,y)$位置表示。另外，我们的数据点还用一种颜色表示一个**类型标签**，一共有两种类型，分别用两种颜色表示。我们想根据这些特征和标签创建一个模型，帮助我们判断新的数据点是“蓝色”还是“红色”。
虽然有很多可以解决分类任务的模型，但这里还是先用最简单的一种，假设平面上有一条可以将两种类型分开的直线，直线的两侧分别是一种类型。那么我们的模型其实就是“一条可以分类的直线”，而模型参数其实是直线位置与方向的数值。这些模型参数的最优解都可以通过学习数据获得（也就是机器学习的“学习”），这个过程通常被称为训练模型。
下图是为这组数据分类而训练的模型。
![图片](E:/my_code/py/img/5-2.png)